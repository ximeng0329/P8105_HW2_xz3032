p8105\_hw2\_xz3032
================

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

# Problem 1

Read the Mr. Trashwheel dataset

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = 1,
    range = "A2:N408" ) %>%
    janitor::clean_names() %>%
    drop_na(dumpster) %>%
    mutate(
      sports_balls = round(sports_balls,0),
      sports_balls = as.integer(sports_balls)
    )
```

Read precipitation data for 2018 and 2017

``` r
p2018 = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                   sheet = "2018 Precipitation",
                   skip = 1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

p2017 = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                   sheet = "2017 Precipitation",
                   skip = 1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine the annual precipitation dataframe

``` r
month_df = tibble(
  month = 1:12,
  month_name = month.abb
)

precip_df = bind_rows(p2018, p2017)

precip_df = left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

\#Problem 2

Read NYC transit data

``` r
transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, entry, vending, entrance_type, ada, starts_with("route")) %>%
  mutate(entry = recode(entry, `YES` = TRUE , `NO` = FALSE)) %>%
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route" ,
    values_to = "route_number"
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

# Short Descripe of the Dataset

The data set contains variables: line, station\_name, station\_latitude,
station\_longitude, entry, vending, entrance\_type, ada, route\_name,
route\_number. I first cleaned the data by gave variables clean names
using janitor::clean\_names function. Then I select the variables I
need. I also changed the entry variables from character to logical.
Finally I combined routes variables and made the data from into a longer
version. The data set dimension is 20548\*`r ncol(transit_df)`.

# Answer Questions

How many distinct stations are there? (465)

``` r
select(transit_df,line,station_name,ada) %>%
  distinct(line, station_name) %>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   465

How many stations are ADA compliance? (84)

``` r
select(transit_df,line,station_name,ada) %>%
  filter(ada == TRUE) %>%
  distinct(line, station_name) %>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    84

What proportion of station entrances / exits without vending allow
entrance? (759 out of 2013)

``` r
count_1 = select(transit_df, entry, vending) %>%
                filter(entry == TRUE) %>%
                filter(vending == "NO") %>%
                count()
count_2 = select(transit_df, entry, vending) %>%
                filter(vending == "NO") %>%
                count()
count_1/count_2
```

    ##           n
    ## 1 0.3770492

## Problem 3

Clean pols-monnth data

``` r
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(year = as.integer(year),
         month = month.abb[as.factor(month)]) %>%
  mutate(president = case_when(prez_dem == 1 ~ "prez_dem", prez_gop==1  ~ "prez_gop")) %>%
  select(-day, -prez_gop, -prez_dem)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Clean snp data

``` r
snp_df = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
    mutate(year = as.integer(year),
         month = month.abb[as.factor(month)]
         ) %>%
  select(-day) %>%
  relocate(year)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Clean unemployment data

``` r
unemploy_df = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) %>%
   mutate(year = as.integer(year),
          month = month.abb[as.factor(month)])
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Merge snp into rows, and then merge with unemployment dataset

``` r
snp_pols = left_join(pols_month, snp_df, by = c("year", "month"))

final_df = left_join(snp_pols, unemploy_df, by = c("year", "month"))
```

Short Description: “pols-month” has information related to the number of
national politicians who are democratic or republican at any given time.
variables including year, month, gov\_gop, sen\_gop, rep\_gop, gov\_dem,
sen\_dem, rep\_dem, president. The file “snp” contains 2 variables
related to Standard & Poor’s stock market index (S\&P), varibales are
year, month, close. The unemployment data frame contains two variables
including year, month, unemployment. I combined the three data frames by
their same key variables month and year. The final product is a data set
with dimension 822 \* 11. The data are from year 1947, 2015.
